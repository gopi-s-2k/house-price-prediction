{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California House Prising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import hashlib\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "housing = pd.read_csv('./data_store/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing['ocean_proximity'].info()\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing.hist(column=\"median_income\",by=\"ocean_proximity\",bins=25,grid=False,figsize=(20,20))\n",
    "# housing[\"ocean_proximity\"].hist(bins=50,figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.hist(bins=50,figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test set\n",
    "# def test_train_split(*,data:pd.core.frame.DataFrame,test_ratio:int|float):\n",
    "#     shuffled_indices = np.random.permutation(len(data))\n",
    "#     test_set_size = int(len(data)*test_ratio)\n",
    "#     test_indices = shuffled_indices[:test_set_size]\n",
    "#     train_indices = shuffled_indices[test_set_size:]\n",
    "#     return data.iloc[test_indices],data.iloc[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data,train_data = (test_train_split(data=housing,test_ratio=0.2))\n",
    "\n",
    "#histogram\n",
    "# housing_with_id.hist(bins=50,figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_set_check(identifier,test_ratio,hash):\n",
    "#     return hash(np.int64(identifier)).digest()[-1] < (256 * test_ratio )\n",
    "# def test_train_split(data,test_ratio,id_column,hash=hashlib.md5):\n",
    "#     ids = data[id_column]\n",
    "#     in_test_set = ids.apply(lambda id_ : test_set_check(id_,test_ratio,hash))\n",
    "#     return data.loc[~in_test_set],data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this approach uses increasing index column (0,1,2,3,4,5,...) as id. If we go with this we always needs to ensure that new data only appends to the data otherwise this fail to persist train and test data..\n",
    "# housing_with_id = housing.reset_index()\n",
    "# train_set,test_set = test_train_split(housing_with_id,0.2,\"index\")\n",
    "\n",
    "# #this approach uses latitude and longitude to comute an unique id\n",
    "# housing_with_id = housing\n",
    "# housing_with_id[\"id\"] = housing[\"longitude\"]*1000 + housing[\"latitude\"]\n",
    "# train_set,test_set = test_train_split(housing_with_id,0.2,\"id\")\n",
    "# #this approach too is not give absolute uniqueness\n",
    "\n",
    "# using hashing \n",
    "# housing_with_id = housing\n",
    "# housing_with_id['id'] = housing['longitude'].astype('str')+'_'+housing['latitude'].astype('str')\n",
    "# housing_with_id['id'] = housing['id'].apply(lambda _id: abs(hash(_id)))\n",
    "# train_set,test_set = test_train_split(housing_with_id,0.2,\"id\")\n",
    "\n",
    "# using sklearn.model_selection import train_test_split\n",
    "# train_set,test_set = train_test_split(housing,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old method for categorization\n",
    "# categorizer = 3\n",
    "# categorizer = 1.5\n",
    "# housing[\"income_cat\"] = np.ceil(housing[\"median_income\"]/categorizer)\n",
    "# housing[\"income_cat\"] = housing[\"income_cat\"].where(housing[\"income_cat\"]<5,5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new method for categorization\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                                    bins=[0.,1.5,3.0,4.5,6.,np.inf],\n",
    "                                    labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].hist(bins=20,figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_indices,test_indices in split.split(housing,housing[\"income_cat\"]):\n",
    "    # print(train_indices,test_indices)\n",
    "    strat_train_set = housing.loc[train_indices]\n",
    "    strat_test_set = housing.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stratified set income range proportions\n",
    "strat_train_set[\"income_cat\"].value_counts() / len(strat_train_set)\n",
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_test_set,strat_train_set):\n",
    "    set_.drop(\"income_cat\",axis=1,inplace=True,errors='raise')\n",
    "housing_train_set = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(housing_train_set))\n",
    "housing_train_set.plot(kind=\"scatter\",x=\"longitude\",y=\"latitude\",color=\"skyblue\",edgecolors='black')\n",
    "housing_train_set.plot(kind=\"scatter\",x=\"longitude\",y=\"latitude\",color=\"skyblue\",edgecolors='black',alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_set.plot(\n",
    "    kind=\"scatter\",\n",
    "    x=\"longitude\",\n",
    "    y=\"latitude\",\n",
    "    edgecolor=\"navy\",\n",
    "    alpha=0.4,\n",
    "    s=housing_train_set[\"population\"]/100,\n",
    "    label=\"population\",figsize=(10,7),\n",
    "    c=\"median_house_value\",\n",
    "    cmap=plt.get_cmap(\"jet\"),\n",
    ")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(housing_train_set.columns)\n",
    "attributes = ['housing_median_age', 'total_rooms', 'median_income','median_house_value']\n",
    "scatter_matrix(housing_train_set[attributes],figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train_set.plot(kind=\"scatter\",x=\"median_income\",y=\"median_house_value\", alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are creating useful features from fetures that seems not useful\n",
    "\n",
    "housing_train_set[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing_train_set[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing_train_set[\"population_per_household\"] = housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing_train_set.select_dtypes(exclude=['object']).corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\",axis=1)\n",
    "housing_lables = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drops rows with null values in total_bedrooms column\n",
    "# housing.dropna(subset=[\"total_bedrooms\"])\n",
    "\n",
    "# # drops the column total_bedrooms as a whole\n",
    "# housing.drop([\"total_bedrooms\"],axis=1)\n",
    "\n",
    "# # filling emptys with median in total_bedrooms column\n",
    "# bedrooms_median = housing[\"total_bedrooms\"].median()\n",
    "# housing[\"total_bedrooms\"].fillna(bedrooms_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can't always assure that only total_bedrooms column can have a missing values \n",
    "# so we can use sklearn's imputing concept to fill out dataframe \n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num = housing.drop(\"ocean_proximity\",axis=1)\n",
    "\n",
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputer.statistics_)\n",
    "print(housing_num.median().values)\n",
    "print(type(imputer.statistics_ == housing_num.median().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)\n",
    "housing_tr = pd.DataFrame(X,columns=housing_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[\"ocean_proximity\"]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_encoded,housing_categories = housing_cat.factorize()\n",
    "print(housing_cat_encoded[:10])\n",
    "print(housing_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\n",
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys,os\n",
    "# sys.path.append(os.getcwd())\n",
    "from housing_transformers.CombinedAttributesAdder import CombinedAttributesAdder\n",
    "from housing_transformers.DataFrameSelector import DataFrameSelector\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pipeline = Pipeline([\n",
    "#     ('imputer',SimpleImputer(strategy='median')),\n",
    "#     ('attribs_adder',CombinedAttributesAdder()),\n",
    "#     ('std_scaler',StandardScaler()),\n",
    "# ])\n",
    "\n",
    "# housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = list(housing_num)\n",
    "cat_attributes = [\"ocean_proximity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(num_attributes)),\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('attribs_adder',CombinedAttributesAdder()),\n",
    "    ('std_scaler',StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(cat_attributes)),\n",
    "    ('cat_encoder',OneHotEncoder(sparse_output=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\",num_pipeline),\n",
    "    (\"cat_pipeline\",cat_pipeline),\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared,housing_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data  = housing.iloc[:5]\n",
    "some_labeles = housing_lables.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "print(\"predictions : \",lin_reg.predict(some_data_prepared))\n",
    "print(\"labels : \",list(some_labeles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# linear regression mean squared error\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_lables,housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared,housing_lables)\n",
    "tree_reg #underfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decission tree regressor mse\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_lables,housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse #overfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from housing_helper import display_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeRegressor cross validation scores\n",
    "scores = cross_val_score(tree_reg,housing_prepared,housing_lables,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression model cross validation scores\n",
    "lin_scores = cross_val_score(lin_reg,housing_prepared,housing_lables,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared,housing_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest mse (too heavy to fit toook more than 30s to fit |:(| )\n",
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_lables,housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest cross validation \n",
    "# commenting because took ~4min to execute too expensive for my system\n",
    "# forest_scores = cross_val_score(forest_reg,housing_prepared,housing_lables,scoring=\"neg_mean_squared_error\",cv=10)\n",
    "# forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "# display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators':[3,10,30],'max_features':[2,4,6,8]},\n",
    "    {'bootstrap':[False],'n_estimators':[3,10],'max_features':[2,3,4]}\n",
    "]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg,param_grid,cv=5,scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(housing_prepared,housing_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score,params in zip(cvres[\"mean_test_score\"],cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score),params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "# print(len(feature_importances),feature_importances)\n",
    "extra_attribs = [\"rooms_per_hhold\",\"pop_per_hhold\",\"bedrooms_per_room\"]\n",
    "cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\n",
    "cat_one_hot_attributes = list(cat_encoder.categories_[0])\n",
    "attributes = num_attributes+extra_attribs+cat_one_hot_attributes\n",
    "# print(len(attributes),attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(feature_importances,attributes),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (finally!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\",axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test,final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "print(\"Final Root Mean Suqared Error : \",final_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Am I just got pranked ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib,os\n",
    "if not os.path.exists('model_outcomes'):\n",
    "    os.makedirs('model_outcomes')\n",
    "\n",
    "joblib.dump(final_model,\"model_outcomes/housing_predictor_model.pkl\")\n",
    "\n",
    "# to use this import like\n",
    "# housing_predictor_model = joblib.load(\"model_outcomes/housing_predictor_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
